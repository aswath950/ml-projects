{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Chest X-Ray Pneumonia prediction model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Setting directory path to the dataset\n",
    "train_dir = '/Users/aswathsabarri/Desktop/Git Repo/Pneumonia detector/chest_xray/train'\n",
    "test_dir = '/Users/aswathsabarri/Desktop/Git Repo/Pneumonia detector/chest_xray/test'\n",
    "\n",
    "# Preprocessing the images\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='binary')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.3926 - accuracy: 0.8345WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 50s 487ms/step - loss: 0.3926 - accuracy: 0.8345 - val_loss: 0.6820 - val_accuracy: 0.7740\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 44s 444ms/step - loss: 0.1484 - accuracy: 0.9430\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 40s 397ms/step - loss: 0.1329 - accuracy: 0.9485\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 41s 410ms/step - loss: 0.1181 - accuracy: 0.9540\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 37s 372ms/step - loss: 0.0915 - accuracy: 0.9685\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 43s 428ms/step - loss: 0.0832 - accuracy: 0.9694\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 38s 375ms/step - loss: 0.0900 - accuracy: 0.9704\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 38s 374ms/step - loss: 0.0690 - accuracy: 0.9734\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 37s 365ms/step - loss: 0.0601 - accuracy: 0.9785\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 37s 371ms/step - loss: 0.0687 - accuracy: 0.9750\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=100,  # depends on the size of your training set\n",
    "    epochs=10,            # can be adjusted\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=50)  # depends on the size of your test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x13c7a7e20>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.14047605]]\n"
     ]
    }
   ],
   "source": [
    "model.save('pneumonia_detection_model.h5')\n",
    "\n",
    "# For prediction\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "img_path = '/Users/aswathsabarri/Desktop/Git Repo/Pneumonia detector/chest_xray/val/NORMAL/NORMAL2-IM-1427-0001.jpeg'\n",
    "img = image.load_img(img_path, target_size=(150, 150))\n",
    "img_array = image.img_to_array(img) / 255.0\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "prediction = model.predict(img_array)\n",
    "print(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All the images below are Normal\n",
      "Image : NORMAL2-IM-1440-0001.jpeg | Prediction : Normal | Score : 0.0005770325660705566\n",
      "Image : NORMAL2-IM-1437-0001.jpeg | Prediction : Normal | Score : 0.24535581469535828\n",
      "Image : NORMAL2-IM-1431-0001.jpeg | Prediction : Normal | Score : 0.0628671646118164\n",
      "Image : NORMAL2-IM-1436-0001.jpeg | Prediction : Normal | Score : 0.03877553343772888\n",
      "Image : NORMAL2-IM-1430-0001.jpeg | Prediction : Pneumonia | Score : 0.9426052570343018\n",
      "Image : NORMAL2-IM-1438-0001.jpeg | Prediction : Normal | Score : 0.24113687872886658\n",
      "Image : NORMAL2-IM-1442-0001.jpeg | Prediction : Normal | Score : 0.0038035809993743896\n",
      "Image : NORMAL2-IM-1427-0001.jpeg | Prediction : Normal | Score : 0.1404760479927063\n",
      "\n",
      "\n",
      "All the images below are Pnuemonic\n",
      "Image : person1950_bacteria_4881.jpeg | Prediction : Pneumonia | Score : 0.9808032512664795\n",
      "Image : person1951_bacteria_4882.jpeg | Prediction : Pneumonia | Score : 0.9999854564666748\n",
      "Image : person1952_bacteria_4883.jpeg | Prediction : Pneumonia | Score : 0.9996638298034668\n",
      "Image : person1946_bacteria_4874.jpeg | Prediction : Pneumonia | Score : 0.9995415210723877\n",
      "Image : person1947_bacteria_4876.jpeg | Prediction : Pneumonia | Score : 0.9990575313568115\n",
      "Image : person1946_bacteria_4875.jpeg | Prediction : Pneumonia | Score : 0.9999327659606934\n",
      "Image : person1949_bacteria_4880.jpeg | Prediction : Pneumonia | Score : 0.9846831560134888\n",
      "Image : person1954_bacteria_4886.jpeg | Prediction : Pneumonia | Score : 0.615234911441803\n",
      "\n",
      " Accuracy of model 0.9375\n"
     ]
    }
   ],
   "source": [
    "# Predictng All images from the val directory.  Use this block of code directly if only prediction needs to done. \n",
    "# The pretrained weights of the model is stored in 'pneumonia_detection_model.h5' file\n",
    "\n",
    "# Acquiring all val images\n",
    "predict_img_dir_normal = \"/Users/aswathsabarri/Desktop/Git Repo/Pneumonia detector/chest_xray/val/NORMAL\"\n",
    "predict_img_dir_pneumonia = \"/Users/aswathsabarri/Desktop/Git Repo/Pneumonia detector/chest_xray/val/PNEUMONIA\"\n",
    "images_file_normal = os.listdir(predict_img_dir_normal)\n",
    "images_file_pneumonia = os.listdir(predict_img_dir_pneumonia)\n",
    "\n",
    "# Loading saved model which has been trained - \n",
    "model = tf.keras.models.load_model('pneumonia_detection_model.h5')\n",
    "test = []\n",
    "pred = []\n",
    "\n",
    "def predict_image(image_path):\n",
    "    img = image.load_img(image_path,target_size=(150,150))\n",
    "    img_array =  image.img_to_array(img) / 255.0   # Normalizing image values \n",
    "    img_array =  np.expand_dims(img_array, axis = 0)\n",
    "\n",
    "    prediction = model.predict(img_array)\n",
    "    return prediction[0][0]\n",
    "\n",
    "\n",
    "#Iterate over all the images and predict them\n",
    "print(\"All the images below are Normal\")\n",
    "for image_file in images_file_normal:\n",
    "    image_path = os.path.join(predict_img_dir_normal, image_file)\n",
    "    prediction_score = predict_image(image_path)\n",
    "    pred_label = 'Pneumonia'\n",
    "    \n",
    "    test.append(0)\n",
    "    if prediction_score < 0.5:\n",
    "        pred_label = \"Normal\"\n",
    "        pred.append(0)\n",
    "    else:\n",
    "        pred.append(1)\n",
    "\n",
    "    print(f'Image : {image_file} | Prediction : {pred_label} | Score : {prediction_score}' )\n",
    "\n",
    "\n",
    "print(\"\\n\\nAll the images below are Pnuemonic\")\n",
    "for image_file in images_file_pneumonia:\n",
    "    image_path = os.path.join(predict_img_dir_pneumonia, image_file)\n",
    "    prediction_score = predict_image(image_path)\n",
    "    pred_label = 'Pneumonia'\n",
    "    \n",
    "    test.append(1)\n",
    "    if prediction_score < 0.5:\n",
    "        pred_label = \"Normal\"\n",
    "        pred.append(0)\n",
    "    else:\n",
    "        pred.append(1)\n",
    "\n",
    "    print(f'Image : {image_file} | Prediction : {pred_label} | Score : {prediction_score}' )\n",
    "\n",
    "\n",
    "print(f\"\\n Accuracy of model {accuracy_score(test,pred)}\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
