{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 6 - Modern Regression Algorithms - Least Square, Ridge and LASSO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score,cross_val_predict\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from numpy import mean\n",
    "from numpy import absolute\n",
    "from numpy import sqrt\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52396, 281)\n",
      "(213, 281)\n"
     ]
    }
   ],
   "source": [
    "# Importing Train and Test datasets\n",
    "\n",
    "df_train = pd.read_csv(\"BlogFeedback/blogData_train.csv\")\n",
    "\n",
    "print(df_train.shape)\n",
    "\n",
    "# print(df.columns)\n",
    "\n",
    "\n",
    "df_test = pd.read_csv(\"BlogFeedback/blogData_test-2012.03.31.01_00.csv\")\n",
    "print(df_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for least sq regression with 10 fold training validation 0.5952857076952146\n",
      "RMSE for least sq regression with 10 fold testing validation 30.523293501011608\n"
     ]
    }
   ],
   "source": [
    "# Least Square regression\n",
    "cross_val = KFold(n_splits = 10, random_state = 45, shuffle = True)\n",
    "\n",
    "least_Squares_model = LinearRegression()\n",
    "\n",
    "x_train = df_train.iloc[:,0:-1]\n",
    "y_train = df_train.iloc[:,-1]\n",
    "\n",
    "ls_train_scores = cross_val_score(least_Squares_model,x_train,y_train, cv= cross_val, n_jobs = -1)\n",
    "\n",
    "print(\"RMSE for least sq regression with 10 fold training validation\",sqrt(mean(absolute(ls_train_scores))))\n",
    "\n",
    "\n",
    "x_test = df_test.iloc[:,0:-1]\n",
    "y_test = df_test.iloc[:,-1]\n",
    "ls_test_scores = cross_val_predict(estimator = least_Squares_model,X = x_test,y = y_test, cv = 10 )\n",
    "\n",
    "print(\"RMSE for least sq regression with 10 fold testing validation\",sqrt(mean(absolute(ls_test_scores))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for Ridge regression with 10 fold training validation 3.0828863246694325\n",
      "RMSE for Ridge regression with 10 fold testing validation 6.155131152858649\n"
     ]
    }
   ],
   "source": [
    "# Ridge Regression\n",
    "\n",
    "ridge_model = Ridge(alpha = 1.0)\n",
    "\n",
    "\n",
    "ridge_train_scores = cross_val_score(ridge_model,x_train,y_train,scoring='neg_mean_absolute_error', cv= cross_val, n_jobs = -1)\n",
    "\n",
    "print(\"RMSE for Ridge regression with 10 fold training validation\",sqrt(mean(absolute(ridge_train_scores))))\n",
    "\n",
    "\n",
    "ridge_test_scores = cross_val_predict(estimator = ridge_model,X = x_test,y = y_test, cv = 10 )\n",
    "\n",
    "print(\"RMSE for Ridge regression with 10 fold testing validation\",sqrt(mean(absolute(ridge_test_scores))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for LASSO regression with 10 fold training validation 3.0178866752410873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.632e+04, tolerance: 4.860e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.991e+03, tolerance: 4.222e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.504e+04, tolerance: 4.861e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.632e+03, tolerance: 4.833e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.673e+04, tolerance: 4.850e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.113e+04, tolerance: 4.809e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.109e+01, tolerance: 9.438e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.425e+04, tolerance: 4.715e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.931e+04, tolerance: 4.861e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for LASSO regression with 10 fold testing validation 4.695962813250412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.598e+04, tolerance: 4.861e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "# LASSO regression\n",
    "\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "ConvergenceWarning('ignore')\n",
    "\n",
    "lasso_model = Lasso(alpha = 1.0,max_iter = 10000)\n",
    "\n",
    "\n",
    "lasso_train_scores = cross_val_score(lasso_model,x_train,y_train,scoring='neg_mean_absolute_error', cv= cross_val, n_jobs = -1)\n",
    "\n",
    "print(\"RMSE for LASSO regression with 10 fold training validation\",sqrt(mean(absolute(lasso_train_scores))))\n",
    "\n",
    "\n",
    "lasso_test_scores = cross_val_predict(estimator = lasso_model,X = x_test,y = y_test, cv = 10 )\n",
    "\n",
    "print(\"RMSE for LASSO regression with 10 fold testing validation\",sqrt(mean(absolute(lasso_test_scores))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The important column nos returned through LASSO model are:\n",
      "1\n",
      "4\n",
      "5\n",
      "9\n",
      "24\n",
      "51\n",
      "54\n",
      "61\n",
      "279\n"
     ]
    }
   ],
   "source": [
    "# Important Attributes of Dataframe\n",
    "lasso_model_2 = Lasso(alpha = 1.0,max_iter = 10000)\n",
    "\n",
    "lasso_model_2.fit(x_train,y_train)\n",
    "\n",
    "lasso_coeffs = lasso_model_2.coef_\n",
    "\n",
    "count = 0\n",
    "print(\"The important column nos returned through LASSO model are:\")\n",
    "for col in lasso_coeffs:\n",
    "\n",
    "    if col > 0:\n",
    "        print(count)\n",
    "\n",
    "    count +=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
